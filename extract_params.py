"""
å‚æ•°æå–å·¥å…· - æ ¹æ®é¢„å®šä¹‰å‚æ•°åˆ—è¡¨ä»PDFä¸­æå–å‚æ•°

åŠŸèƒ½ï¼š
1. è¯»å–é¢„å®šä¹‰çš„å‚æ•°åˆ—è¡¨ï¼ˆparams_list.txtï¼‰
2. ä½¿ç”¨Doclingå°†PDFè½¬æ¢ä¸ºHTML
3. è°ƒç”¨å¤§æ¨¡å‹ä»æ–‡æ¡£ä¸­æå–æŒ‡å®šçš„å‚æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
1. åœ¨ params_list.txt ä¸­å¡«å†™éœ€è¦æå–çš„å‚æ•°åç§°ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰
2. ä¿®æ”¹ PDF_PATH ä¸ºç›®æ ‡PDFæ–‡ä»¶è·¯å¾„
3. è¿è¡Œè„šæœ¬ï¼špython extract_params.py
"""

import json
import os
import re
from datetime import datetime
from pathlib import Path

from docling.document_converter import DocumentConverter
from jinja2 import Template

from meri.utils.llm_utils import complete_chat
from meri.utils.docling_utils import export_to_html


# ============================================================
# é…ç½®åŒºåŸŸ
# ============================================================

# å¾…æå–çš„PDFæ–‡ä»¶è·¯å¾„
PDF_PATH = "data/demo_data/final.pdf"

# é¢„å®šä¹‰å‚æ•°åˆ—è¡¨æ–‡ä»¶
PARAMS_FILE = "params_list.txt"

# ä½¿ç”¨çš„æ¨¡å‹
MODEL = "qwen/qwen3-max"

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "output"

# æ¯ä¸ªåˆ†å—çš„æœ€å¤§å­—ç¬¦æ•°ï¼ˆæ ¹æ®æ¨¡å‹tokené™åˆ¶è°ƒæ•´ï¼‰
MAX_CHARS = 20000

# æ¯æ‰¹å¤„ç†çš„å‚æ•°æ•°é‡ï¼ˆé¿å…å‚æ•°åˆ—è¡¨è¿‡é•¿ï¼‰
PARAMS_BATCH_SIZE = 50


# ============================================================
# æå–Prompt
# ============================================================
EXTRACTION_PROMPT = Template("""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µæ°”è®¾å¤‡æŠ€æœ¯æ–‡æ¡£å‚æ•°æå–ä¸“å®¶ã€‚

## æ ¸å¿ƒä»»åŠ¡
ä»æ–‡æ¡£ä¸­ç²¾ç¡®æå–æŒ‡å®šçš„æŠ€æœ¯å‚æ•°ã€‚å¿…é¡»ä»”ç»†é˜…è¯»æ–‡æ¡£ä¸­çš„æ¯ä¸ªè¡¨æ ¼å’Œæ®µè½ã€‚

## éœ€è¦æå–çš„å‚æ•°åˆ—è¡¨ï¼ˆå…± {{ params_count }} ä¸ªï¼Œè¯·é€ä¸€æŸ¥æ‰¾ï¼‰
{{ params_list }}

## æ–‡æ¡£å†…å®¹
{{ document }}

## å…³é”®æå–è§„åˆ™

### 1. è¡¨æ ¼å¤„ç†ï¼ˆæœ€é‡è¦ï¼‰
- æŠ€æœ¯å‚æ•°é€šå¸¸åœ¨è¡¨æ ¼ä¸­ï¼Œè¡¨æ ¼ç¬¬ä¸€åˆ—æ˜¯å‚æ•°åï¼Œåé¢åˆ—æ˜¯æ•°å€¼
- è¡¨æ ¼å¯èƒ½æœ‰å¤šçº§è¡¨å¤´ï¼Œå¦‚"æ–­è·¯å™¨"ä¸‹æœ‰"åˆ†é—¸æ—¶é—´"ã€"åˆé—¸æ—¶é—´"ç­‰å­å‚æ•°
- ä»”ç»†è¯†åˆ«è¡¨æ ¼ç»“æ„ï¼Œæ­£ç¡®å…³è”å‚æ•°åå’Œæ•°å€¼

### 2. è®¾å¤‡åŒºåˆ†ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
å‚æ•°åˆ—è¡¨ä¸­çš„å‚æ•°åå·²åŒ…å«è®¾å¤‡åç§°ï¼Œå¿…é¡»ç²¾ç¡®åŒ¹é…ï¼š
- "æ–­è·¯å™¨åˆ†é—¸æ—¶é—´" - åªæå–æ–­è·¯å™¨çš„åˆ†é—¸æ—¶é—´
- "éš”ç¦»å¼€å…³åˆ†é—¸æ—¶é—´" - åªæå–éš”ç¦»å¼€å…³çš„åˆ†é—¸æ—¶é—´
- "å¿«é€Ÿæ¥åœ°å¼€å…³åˆ†é—¸æ—¶é—´" - åªæå–å¿«é€Ÿæ¥åœ°å¼€å…³çš„åˆ†é—¸æ—¶é—´
- "æ£€ä¿®æ¥åœ°å¼€å…³æœºæ¢°ç¨³å®šæ€§" - åªæå–æ£€ä¿®æ¥åœ°å¼€å…³çš„æœºæ¢°ç¨³å®šæ€§
ä¸åŒè®¾å¤‡çš„åŒåå‚æ•°æ˜¯ä¸åŒçš„å‚æ•°ï¼

### 3. è¯­ä¹‰åŒ¹é…
æ–‡æ¡£ä¸­çš„è¡¨è¿°å¯èƒ½ä¸åˆ—è¡¨ç•¥æœ‰ä¸åŒï¼Œç†è§£è¯­ä¹‰ååŒ¹é…ï¼š
- "æ—¶é—´å‚æ•°-åˆ†é—¸æ—¶é—´" â†’ "åˆ†é—¸æ—¶é—´"
- "é¢å®šçŸ­è·¯å¼€æ–­ç”µæµ(äº¤æµåˆ†é‡)" â†’ "é¢å®šçŸ­è·¯å¼€æ–­ç”µæµäº¤æµåˆ†é‡"
- "ä¸»å›è·¯æ¥è§¦ç”µé˜»" â†’ "ä¸»å›è·¯ç”µé˜»"
- "æœºæ¢°ç¨³å®šæ€§(æ¬¡)" â†’ "æœºæ¢°ç¨³å®šæ€§"

### 4. æ•°å€¼æå–
- æå–å®Œæ•´æ•°å€¼ï¼ŒåŒ…æ‹¬ç¬¦å·ï¼šâ‰¤28msã€â‰¥10000æ¬¡ã€4.8~5.8m/s
- æ•°å€¼å’Œå•ä½è¦å®Œæ•´ï¼š40kAã€3sã€1000kg

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰
```json
{
    "parameters": [
        {
            "name": "ä½¿ç”¨å‚æ•°åˆ—è¡¨ä¸­çš„åŸå§‹åç§°",
            "value": "æ•°å€¼ï¼ˆå«ç¬¦å·å¦‚â‰¤â‰¥ï¼‰",
            "unit": "å•ä½",
            "original_text": "æ–‡æ¡£ä¸­çš„åŸå§‹è¡¨è¿°ï¼ˆå«è®¾å¤‡åï¼‰"
        }
    ],
    "not_found": ["åœ¨æœ¬æ®µæ–‡æ¡£ä¸­æœªæ‰¾åˆ°çš„å‚æ•°"]
}
```

## é‡è¦æç¤º
1. é€ä¸€æ£€æŸ¥å‚æ•°åˆ—è¡¨ä¸­çš„æ¯ä¸ªå‚æ•°ï¼Œç¡®ä¿ä¸é—æ¼
2. è¡¨æ ¼ä¸­çš„å‚æ•°å°¤å…¶è¦ä»”ç»†ï¼Œå¾ˆå¤šå‚æ•°éƒ½åœ¨è¡¨æ ¼é‡Œ
3. å¦‚æœåŒä¸€å‚æ•°åœ¨ä¸åŒè®¾å¤‡ä¸‹æœ‰å€¼ï¼Œåªæå–ä¸å‚æ•°ååŒ¹é…çš„é‚£ä¸ªè®¾å¤‡çš„å€¼
4. åªè¾“å‡ºJSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹
""")


class ParamsExtractor:
    """å‚æ•°æå–å™¨"""
    
    def __init__(self, model: str = MODEL):
        self.model = model
        self.converter = DocumentConverter()
        self.params_list = []
    
    def load_params_list(self, params_file: str):
        """åŠ è½½é¢„å®šä¹‰å‚æ•°åˆ—è¡¨"""
        print(f"ğŸ“‚ åŠ è½½å‚æ•°åˆ—è¡¨: {params_file}")
        with open(params_file, "r", encoding="utf-8") as f:
            lines = f.readlines()
        
        self.params_list = [line.strip() for line in lines if line.strip()]
        print(f"  âœ“ åŠ è½½äº† {len(self.params_list)} ä¸ªå‚æ•°")
    
    def _convert_to_html(self, file_path: str) -> str:
        """å°†æ–‡æ¡£è½¬æ¢ä¸ºHTML"""
        print(f"ğŸ“„ è½¬æ¢æ–‡æ¡£: {file_path}")
        result = self.converter.convert(file_path)
        html_content = export_to_html(result.document)
        print(f"  âœ“ è½¬æ¢å®Œæˆï¼ŒHTMLé•¿åº¦: {len(html_content)} å­—ç¬¦")
        return html_content
    
    def _chunk_document(self, html_content: str) -> list:
        """å°†æ–‡æ¡£åˆ†å—"""
        if len(html_content) <= MAX_CHARS:
            return [html_content]
        
        chunks = []
        current_pos = 0
        
        while current_pos < len(html_content):
            end_pos = min(current_pos + MAX_CHARS, len(html_content))
            
            if end_pos < len(html_content):
                # å°è¯•åœ¨åˆé€‚çš„ä½ç½®æ–­å¼€
                for tag in ['</table>', '</div>', '</p>', '<br', '\n\n']:
                    find_pos = html_content.rfind(tag, current_pos, end_pos)
                    if find_pos > current_pos + MAX_CHARS // 2:
                        end_pos = find_pos + len(tag)
                        break
            
            chunk = html_content[current_pos:end_pos]
            chunks.append(chunk)
            current_pos = end_pos
        
        print(f"  ğŸ“¦ æ–‡æ¡£åˆ†ä¸º {len(chunks)} ä¸ªå—")
        return chunks
    
    def _chunk_params(self, params: list) -> list:
        """å°†å‚æ•°åˆ—è¡¨åˆ†æ‰¹"""
        if len(params) <= PARAMS_BATCH_SIZE:
            return [params]
        
        batches = []
        for i in range(0, len(params), PARAMS_BATCH_SIZE):
            batches.append(params[i:i + PARAMS_BATCH_SIZE])
        
        return batches
    
    def _call_llm(self, prompt: str) -> dict:
        """è°ƒç”¨å¤§æ¨¡å‹"""
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£å‚æ•°æå–ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¾“å‡ºJSONæ ¼å¼ã€‚"},
            {"role": "user", "content": [{"type": "text", "text": prompt}]}
        ]
        
        for attempt in range(3):
            try:
                response = complete_chat(
                    model=self.model,
                    messages=messages,
                    temperature=0.1,
                    response_format={"type": "json_object"},
                    max_tokens=8192
                )
                
                return json.loads(response)
                
            except json.JSONDecodeError as e:
                if attempt < 2:
                    print(f"    âš ï¸ JSONè§£æå¤±è´¥ï¼Œé‡è¯•ä¸­...")
                    continue
                # å°è¯•ä¿®å¤JSON
                return self._try_fix_json(response)
            except Exception as e:
                if attempt < 2:
                    print(f"    âš ï¸ è°ƒç”¨å¤±è´¥: {str(e)[:50]}ï¼Œé‡è¯•ä¸­...")
                    continue
                raise
        
        return {"parameters": [], "not_found": []}
    
    def _try_fix_json(self, response: str) -> dict:
        """å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON"""
        try:
            # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å¯¹è±¡
            if '"parameters"' in response:
                # æ‰¾åˆ°parametersæ•°ç»„çš„å¼€å§‹
                start = response.find('"parameters"')
                if start > 0:
                    # å°è¯•è¡¥å…¨
                    fixed = response.rstrip()
                    if not fixed.endswith('}'):
                        fixed += '],"not_found":[]}'
                    return json.loads(fixed)
        except:
            pass
        return {"parameters": [], "not_found": []}
    
    def _normalize_name(self, name: str) -> str:
        """æ ‡å‡†åŒ–å‚æ•°åï¼Œç”¨äºåŒ¹é…"""
        # ç§»é™¤å¸¸è§çš„åˆ†éš”ç¬¦å’Œç©ºæ ¼
        normalized = name.replace("-", "").replace("ï¼", "").replace("â€”", "")
        normalized = normalized.replace("(", "").replace(")", "")
        normalized = normalized.replace("ï¼ˆ", "").replace("ï¼‰", "")
        normalized = normalized.replace(" ", "").replace("ã€€", "")
        normalized = normalized.replace("/", "").replace("ã€", "")
        return normalized.lower()
    
    def _match_param_name(self, extracted_name: str, params_batch: list) -> str:
        """åŒ¹é…æå–çš„å‚æ•°ååˆ°é¢„å®šä¹‰åˆ—è¡¨"""
        extracted_norm = self._normalize_name(extracted_name)
        
        # 1. ç²¾ç¡®åŒ¹é…
        for p in params_batch:
            if extracted_name == p:
                return p
        
        # 2. æ ‡å‡†åŒ–åç²¾ç¡®åŒ¹é…
        for p in params_batch:
            if self._normalize_name(p) == extracted_norm:
                return p
        
        # 3. åŒ…å«åŒ¹é…ï¼ˆéœ€è¦è®¾å¤‡åä¹ŸåŒ¹é…ï¼‰
        # æå–è®¾å¤‡å
        devices = ["æ–­è·¯å™¨", "éš”ç¦»å¼€å…³", "å¿«é€Ÿæ¥åœ°å¼€å…³", "æ£€ä¿®æ¥åœ°å¼€å…³", "ç”µæµäº’æ„Ÿå™¨", "ç”µå‹äº’æ„Ÿå™¨", "é¿é›·å™¨"]
        
        extracted_device = None
        for d in devices:
            if d in extracted_name:
                extracted_device = d
                break
        
        for p in params_batch:
            p_norm = self._normalize_name(p)
            
            # æ£€æŸ¥è®¾å¤‡æ˜¯å¦åŒ¹é…
            p_device = None
            for d in devices:
                if d in p:
                    p_device = d
                    break
            
            # å¦‚æœä¸¤è€…éƒ½æœ‰è®¾å¤‡åï¼Œå¿…é¡»åŒ¹é…
            if extracted_device and p_device:
                if extracted_device != p_device:
                    continue
            
            # æ£€æŸ¥å‚æ•°åæ ¸å¿ƒéƒ¨åˆ†æ˜¯å¦åŒ¹é…
            if extracted_norm in p_norm or p_norm in extracted_norm:
                return p
        
        return None
    
    def _extract_batch(self, html_chunk: str, params_batch: list) -> dict:
        """å¯¹ä¸€ä¸ªæ–‡æ¡£å—å’Œä¸€æ‰¹å‚æ•°è¿›è¡Œæå–"""
        params_str = "\n".join([f"- {p}" for p in params_batch])
        
        prompt = EXTRACTION_PROMPT.render(
            params_list=params_str,
            params_count=len(params_batch),
            document=html_chunk
        )
        
        return self._call_llm(prompt)
    
    def extract(self, file_path: str) -> dict:
        """æ‰§è¡Œæå–"""
        print(f"\n{'='*60}")
        print(f"ğŸ” å‚æ•°æå–ï¼ˆé¢„å®šä¹‰åˆ—è¡¨æ¨¡å¼ï¼‰")
        print(f"{'='*60}")
        print(f"æ–‡ä»¶: {file_path}")
        print(f"å‚æ•°æ•°: {len(self.params_list)}")
        print(f"æ¨¡å‹: {self.model}")
        
        # è½¬æ¢æ–‡æ¡£
        html_content = self._convert_to_html(file_path)
        
        # åˆ†å—
        doc_chunks = self._chunk_document(html_content)
        params_batches = self._chunk_params(self.params_list)
        
        print(f"\nğŸ“Š å¤„ç†è®¡åˆ’:")
        print(f"  æ–‡æ¡£å—æ•°: {len(doc_chunks)}")
        print(f"  å‚æ•°æ‰¹æ¬¡: {len(params_batches)}")
        
        # æ”¶é›†ç»“æœ
        all_params = {}  # name -> param dict
        found_params = set()
        
        # å¯¹æ¯ä¸ªæ–‡æ¡£å—ï¼Œç”¨æ‰€æœ‰å¾…æŸ¥å‚æ•°è¿›è¡Œæå–
        for chunk_idx, chunk in enumerate(doc_chunks):
            # è®¡ç®—å½“å‰è¿˜éœ€è¦æŸ¥æ‰¾çš„å‚æ•°
            remaining_params = [p for p in self.params_list if p not in found_params]
            
            if not remaining_params:
                print(f"\nâœ… æ‰€æœ‰å‚æ•°å·²æ‰¾åˆ°ï¼Œè·³è¿‡å‰©ä½™æ–‡æ¡£å—")
                break
            
            print(f"\nğŸ”„ å¤„ç†æ–‡æ¡£å— {chunk_idx + 1}/{len(doc_chunks)} (å¾…æŸ¥å‚æ•°: {len(remaining_params)})")
            
            # å¦‚æœå¾…æŸ¥å‚æ•°å¤ªå¤šï¼Œåˆ†æ‰¹å¤„ç†
            param_batches = self._chunk_params(remaining_params)
            
            for batch_idx, params_batch in enumerate(param_batches):
                if len(param_batches) > 1:
                    print(f"  ğŸ“¦ å‚æ•°æ‰¹æ¬¡ {batch_idx + 1}/{len(param_batches)}")
                
                try:
                    result = self._extract_batch(chunk, params_batch)
                    
                    # å¤„ç†ç»“æœ
                    chunk_found = 0
                    for param in result.get("parameters", []):
                        if not isinstance(param, dict):
                            continue
                        
                        name = param.get("name", "")
                        value = param.get("value")
                        
                        # è¿‡æ»¤ç©ºå€¼
                        if not name or not value or str(value).strip() in ["", "null", "æ— ", "æœªæ‰¾åˆ°", "N/A", "-"]:
                            continue
                        
                        # ç²¾ç¡®åŒ¹é…é¢„å®šä¹‰åˆ—è¡¨ä¸­çš„å‚æ•°
                        matched_name = self._match_param_name(name, params_batch)
                        
                        if matched_name and matched_name not in found_params:
                            param["name"] = matched_name  # ä½¿ç”¨æ ‡å‡†åç§°
                            all_params[matched_name] = param
                            found_params.add(matched_name)
                            chunk_found += 1
                    
                    print(f"    âœ“ æœ¬æ‰¹æ‰¾åˆ° {chunk_found} ä¸ªå‚æ•°")
                    
                except Exception as e:
                    print(f"    âœ— å¤„ç†å¤±è´¥: {e}")
        
        # æŒ‰é¢„å®šä¹‰é¡ºåºæ•´ç†ç»“æœ
        ordered_params = []
        not_found = []
        
        for param_name in self.params_list:
            if param_name in all_params:
                ordered_params.append(all_params[param_name])
            else:
                not_found.append(param_name)
        
        # ç»Ÿè®¡
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æå–ç»“æœç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"  é¢„å®šä¹‰å‚æ•°:   {len(self.params_list)}")
        print(f"  æˆåŠŸæå–:     {len(ordered_params)}")
        print(f"  æœªæ‰¾åˆ°:       {len(not_found)}")
        
        result = {
            "source_file": file_path,
            "params_file": PARAMS_FILE,
            "extraction_time": datetime.now().isoformat(),
            "model": self.model,
            "statistics": {
                "total_requested": len(self.params_list),
                "found": len(ordered_params),
                "not_found": len(not_found)
            },
            "parameters": ordered_params,
            "not_found": not_found
        }
        
        return result


def main():
    """ä¸»å‡½æ•°"""
    print(f"\n{'='*60}")
    print(f"å‚æ•°æå–å·¥å…·")
    print(f"{'='*60}")
    print(f"PDFæ–‡ä»¶: {PDF_PATH}")
    print(f"å‚æ•°åˆ—è¡¨: {PARAMS_FILE}")
    print(f"æ¨¡å‹: {MODEL}")
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(PDF_PATH):
        print(f"\nâŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {PDF_PATH}")
        return
    
    if not os.path.exists(PARAMS_FILE):
        print(f"\nâŒ å‚æ•°åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {PARAMS_FILE}")
        return
    
    # åˆ›å»ºæå–å™¨
    extractor = ParamsExtractor(model=MODEL)
    
    # åŠ è½½å‚æ•°åˆ—è¡¨
    extractor.load_params_list(PARAMS_FILE)
    
    # æ‰§è¡Œæå–
    result = extractor.extract(PDF_PATH)
    
    # ä¿å­˜ç»“æœ
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    timestamp = datetime.now().strftime("%m_%d_%H%M")
    output_file = os.path.join(OUTPUT_DIR, f"extraction_{timestamp}.json")
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æå–ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœé¢„è§ˆ
    if result["parameters"]:
        print(f"\nğŸ“‹ æå–ç»“æœé¢„è§ˆï¼ˆå‰10ä¸ªï¼‰:")
        for param in result["parameters"][:10]:
            print(f"  - {param.get('name')}: {param.get('value')}{param.get('unit', '')}")
        if len(result["parameters"]) > 10:
            print(f"  ... è¿˜æœ‰ {len(result['parameters']) - 10} ä¸ª")
    
    # æ˜¾ç¤ºæœªæ‰¾åˆ°çš„å‚æ•°
    if result["not_found"]:
        print(f"\nâš ï¸ æœªæ‰¾åˆ°çš„å‚æ•° ({len(result['not_found'])}ä¸ª):")
        for name in result["not_found"][:10]:
            print(f"  - {name}")
        if len(result["not_found"]) > 10:
            print(f"  ... è¿˜æœ‰ {len(result['not_found']) - 10} ä¸ª")


if __name__ == "__main__":
    main()
